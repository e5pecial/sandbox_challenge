# sandbox_challenge
https://mlbootcamp.ru/round/14/sandbox/


## Предсказание прогноза отклика аудитории на интернет-опрос

### Метрика: ROC-AUC

### Получил На лидерборде песочницы скор:
```
П: 0.7458305
4 / 15
Ф: 0.7447829
4 / 15
```

На решение потратил примерно около трех вечеров -- причем один из вечеров был уделен чисто предобработке данных.

### Структура:
* [preparing](preparing.ipynb) -- предобработка данных (tf-idf и countvectorizer)
* [baseline](baseline.ipynb) -- просто логрег в качестве бейзлайна
* [lgbm_folds](lgbm_folds.ipynb) -- усреднение предсказания градиентного бустинга на 10 фолдах
* [features](features.ipynb) -- добавил еще численных фич к имеющимся sparse-матрицам
* [lgbm_folds_with_numeric](lgbm_folds_with_numeric.ipynb) -- градиентный бустинг на 10 фолдах по расширенному датасету с новыми фичами

Отдельно еще делал EDA, гридсерч для подбора гиперпараметров для LGBM, пробовал разные векторайзеры для sparse фич

### Финальный предикт: блединг `logreg*0.05 + lgbm_10_folds*0.95`

Есть куда еще улучшать:
Покрутить гиперпараметры, сделать еще несколько независимых разных моделей для блендинга (например, обучить еще xgboost и catboost, плюс обучить модель на данных, на которых попробовать уменьшить размерность или кластеризовать), 
Можно еще попробовать многоуровневый стекинг.

Также можно подумать и добавить ещё статистических фичей из исходных данных, а для категориальной фичи попробовать впилить таргет энкодинг.
